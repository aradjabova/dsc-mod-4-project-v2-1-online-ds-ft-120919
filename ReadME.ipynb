{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReadME.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN4W5HNHY65VJKsgzG0JxtA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aradjabova/dsc-mod-4-project-v2-1-online-ds-ft-120919/blob/master/ReadME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B6nFOnEUmN6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Pneumonia Image Classification\n",
        "\n",
        "Using the OSEM process we will build a image classifier to predict if a patient has pneumonia (based on their x-rays). We are building this model in the hope of reducing human error in reading the x-rays of patients. \n",
        "\n",
        "This is an unbalanced binary-class classification problem; because of this we will be creating addition augmented photos of the normal lungs.\n",
        "\n",
        "\n",
        "<img  src=\"https://drive.google.com/uc?id=1QyT6dlq-Ikn1JWKg13c-Ybobk7M4ZLva\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTzTA3T_UmKN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Obtaining and Scrubbing\n",
        "<details>\n",
        "  <summary>Click to read about getting and cleaning the data! </summary>\n",
        "  \n",
        "  ## Obtaining\n",
        "  * We have gathered the data from https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
        "     \n",
        "     \n",
        "  ## Scrubbing\n",
        "  * We have used several different methods to clean the data:\n",
        "      1. Missing data:\n",
        "          * There was plenty of missing data in this dataset;\n",
        "          * Meaning that there were many Pneumonia x-rays and almost 1/3 the amount of normal x-rays\n",
        "      2. Dealing with Missing Data\n",
        "        * In order to combat the missing data; we created additional random images of the normal xrays that were augmented.\n",
        "        Each randomly selected images was altered into 20 different images with different zoom, shear, rotation, flips and etc. \n",
        "      4. Dataset:\n",
        "          * Once the training data was balanced we were created dataframes for easy readibility\n",
        "\n",
        "\n",
        "<img  src=\"https://drive.google.com/uc?id=1jqChtIUCcGFLTPwoE2A2WG5oi520Lb3v\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUttfd_9UmE_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Explore\n",
        "<details>\n",
        "  <summary>Click to read about exploration of the data! </summary>\n",
        "  \n",
        "  ## Exploring\n",
        "  * While exploring the data, there are some extremely difficult differences between the normal and pneumonia x-rays that would be hard to see\n",
        "  * To get a better understanding of the different images of the xrays, we opened a few of each of the normal and pneumonia x-rays.\n",
        "  \n",
        "Normal\n",
        "  <img style=\"float: left;\" src=\"https://drive.google.com/uc?id=1UJmM4bXrfxVIXlo1htkAOFqAhgTUjHdt\" >\n",
        "\n",
        "Pneumonia\n",
        "  <img style=\"float: left;\" src=\"https://drive.google.com/uc?id=1C078gPhXNM7G-L7-yU3j2WYB_D3Mp0LK\" >\n",
        "  \n",
        "  \n",
        "  \n",
        "  <p>\n",
        "    \n",
        "  For a better visualization of the differnt x-rays (the augmented ones and the original ones), we can look at the below graphs that show a variety of each of the targets\n",
        "\n",
        "  Normal\n",
        "  <img style=\"float: left;\" src=\"https://drive.google.com/uc?id=1UBfxI6QUzpKtAyDwmS74ReXidUZEef_O\" >\n",
        "   \n",
        "\n",
        "\n",
        "   Pneumonia\n",
        "   <img style=\"float: left;\" src=\"https://drive.google.com/uc?id=10YVEs7lESRiCjJHNAsWCbzFkqNl1t86e\" >\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   As you can see, the augmented images are also present in our normal x-rays. These images allow the model to train equally and intensively on the variety of the normal x-rays with the pnemonia ones.\n",
        "   </p>\n",
        "  \n",
        "     \n",
        "        \n",
        "        \n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkZKsGlLUl6u",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Model\n",
        "<details>\n",
        "  <summary>Click to read about modeling the data! </summary>\n",
        "  \n",
        "  ## Modeling\n",
        "  To model our data effectively; we created a image classifier with many layers.\n",
        "\n",
        "   <img style=\"float: center;\" src=\"https://drive.google.com/uc?id=1C0Ibf3Tc8V0-KOCrhDc1niSvJV5cyZK8\" >\n",
        "\n",
        "\n",
        "  * Conv2D \n",
        "\n",
        "    * Scans the image and takes each pixel value in a 3x3 (or 4x4, depends on setting) part and multiplies it by a certain weight, adds the numbers and uses that number as the value of the output image of that pixel\n",
        "    * Depending on the weights, the output image can be blurred, brighter, darker, etc. (basicallu, slight photoshop)\n",
        "\n",
        "  * MaxPooling2\n",
        "    * Resizes the output image\n",
        "    * Takes 2x2 area of a image and chooses the max value in each area\n",
        "    * Shrinks the image by a factor of two\n",
        "    * After shrinking usually the images are used for additional filters (Conv2D) in order to train on smaller scales to find more patterns\n",
        "  \n",
        "  * Flatten\n",
        "    * Because we will be using Dense next, we need to use Flatten to reduce the number of dimensions to one dimension\n",
        "  \n",
        "  * Dense\n",
        "    * Dense layers are hidden layers that use different acitvation functions to find the weights of each parameter of the image in order to appropriately learn the images\n",
        "\n",
        "  * Dropout\n",
        "    * Usually set to 40%, which means that 40% of the parameters that go into the Dropout are set to zero,\n",
        "    * This helps the model not overfit\n",
        "\n",
        "This leads us to having 823,000 differnt parameters that our model is using and going throught in order to train on the images.\n",
        "  \n",
        "\n",
        "</details>  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4X0HQcDUly_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Interpert\n",
        "<details>\n",
        "  <summary>Click to read about interperting our results! </summary>\n",
        "  \n",
        "  ## Interpreting the results\n",
        "  * The way to interpret the results, is by reviewing the confusion matrices and classification report and the accuracy and loss of the models.. \n",
        "\n",
        "\n",
        "\n",
        "<img style=\"float: left;\" src=\"https://drive.google.com/uc?id=1cOz9oe9N0vCfpvacObvwQMIExrOIrm4r\" >\n",
        "  * The accuracy plots show the accuracy of the model as it is training. It shows the accuracy for the training data for every epoch, as well as the accuracy during the validation steps (which is the test data)\n",
        "  \n",
        "\n",
        "  * The loss plots show the los of the model as it is training. It shows the loss for the training data for every epoch, as well as the loss during the validation steps (which is the test data)\n",
        "  <img style=\"float: left;\" src=\"https://drive.google.com/uc?id=1-QGPyNwwubHz8UAmyNnaNn7lp5QfIe7P\" >\n",
        "\n",
        "\n",
        "\n",
        "  * The confusion matrices tells us how well the model performed on the test data by showing us the results of the classification. It shows the number of correct and the number of incorrect classifications\n",
        "  <img style=\"float: left;\" src=\"https://drive.google.com/uc?id=1uBVhuLttDoT6xEFvs3v_foNuSAxGZl0y\" >\n",
        "    \n",
        "    \n",
        "    * As you can see there the diagonal boxes (from left to right) show the true positive predictions (meaning that the model predicted them and it was correct).\n",
        "    * As shown, there are more x-rays that are predicted as pneumonia instead of normal. \n",
        "    * This is benefical because in regards to the cost and the integrity of this problem, it is better for the model to predict pnemonia for patients to get more test, in order to minimize the loss of life or health\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</details>  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HirPj-_UloX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Future Work\n",
        "<details>\n",
        "  <summary> Click to future work for analysis! </summary>\n",
        "  \n",
        "  ## Future work for Pneumonia X-Rays\n",
        "  \n",
        "  * Obtain more normal x-rays  in order for the models to train better and become more accurate.\n",
        "  * Create deeper models with more layer that can handle learning for longer periods of time and be more accurate\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJd3-WluUofO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Final Project Submission\n",
        "\n",
        "* Student name: Alisa Radjabova\n",
        "* Student pace: Full Time\n",
        "* Scheduled project review date/time: \n",
        "* Instructor name: Rafael\n",
        "* Blog post URL: \n",
        "* Presentation: \n",
        "* Video : \n",
        "\n"
      ]
    }
  ]
}